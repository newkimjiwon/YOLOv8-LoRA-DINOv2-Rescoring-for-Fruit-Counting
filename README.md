# YOLOv8의 겹침 객체 탐지 성능 개선을 위한 지식 증류 연구

## 1. 프로젝트 개요

### 1.1. 목표
본 프로젝트의 최종 목표는 표준 YOLOv8 모델이 산업 환경의 과일 탐지 시나리오에서 보이는 한계점, 특히 **작거나 서로 겹쳐진 객체**에 대한 탐지 성능 저하 문제를 해결하는 것입니다. 이를 위해 **DINOv2를 선생님 모델(Teacher Model)로 사용하는 지식 증류(Knowledge Distillation)** 기법을 핵심 방법론으로 채택하고, 그 효과를 검증하기 위해 다음과 같은 다른 접근법들과 체계적으로 비교 분석을 수행합니다.

-   **표준 미세조정 (Baseline Fine-tuning)**
-   **LoRA (Low-Rank Adaptation)**
-   **DINOv2 기반 후처리 (Post-processing Rescoring)**

### 1.2. 최종 결론 요약
다양한 실험을 통해, **정량적인 종합 성능 지표(mAP)**에서는 **표준 YOLOv8 모델을 50 에포크 동안 충분히 학습시킨 Baseline**이 가장 높은 점수를 기록했습니다. 하지만, **정성적인 시각 평가** 및 **세부 성능 지표(정밀도, 재현율)** 분석에서는 **DINOv2 지식 증류 모델**이 오탐지를 줄이고 복잡한 상황에서 더 안정적인 탐지 결과를 보여주었습니다. 따라서 실제 산업 현장에서의 신뢰성과 안정성을 우선시한다면, **지식 증류 모델이 본 프로젝트의 목표에 더 부합하는 최종 결과물**이라고 결론 내릴 수 있습니다.


## 2. 문제 정의 및 배경

YOLOv8은 실시간 객체 탐지 분야에서 뛰어난 속도와 정확도를 제공하는 최신 모델입니다. 그러나 일반적인 환경과 달리, 과일이 무작위로 쌓여있는 컨베이어 벨트나 수확 상자와 같은 실제 산업 환경에서는 다음과 같은 문제로 인해 성능이 저하될 수 있습니다.

-   **겹침 문제 (Occlusion) 해결의 필요성**: 여러 과일이 서로를 가리고 쌓여있을 때, YOLOv8은 개별 객체를 명확히 구분하지 못하고 하나의 큰 객체로 잘못 인식하거나, 가려진 객체를 탐지하지 못하는 경우가 빈번하게 발생합니다.
-   **작은 객체 탐지 성능**: 원거리에 위치하거나 품종 자체가 작은 과일들은 이미지 상에서 차지하는 픽셀 수가 적어 탐지율이 현저히 떨어집니다.

이러한 한계는 정확한 수량 파악 및 품질 관리가 필수적인 자동화 공정에서 오작동의 원인이 될 수 있으므로, 반드시 개선이 필요합니다.


## 3. 실험 방법론

본 프로젝트는 위에서 정의된 문제를 해결하기 위해, 다음과 같은 네 가지 주요 접근법을 설계하고 그 성능을 공정하게 비교했습니다. 모든 실험은 재현성을 보장하기 위해 `seed=0`, `deterministic=True` 조건 하에 수행되었습니다.

### 3.1. Baseline (표준 미세조정)
가장 기본적인 접근법으로, 사전 학습된 YOLOv8s 모델의 모든 가중치를 과일 데이터셋에 맞춰 재학습(미세조정)합니다. 이 실험의 결과는 다른 모든 기법의 성능을 평가하는 **성능 기준점(Baseline)** 역할을 합니다.

### 3.2. LoRA (Low-Rank Adaptation)
LoRA는 모델의 거대한 원본 가중치는 변경하지 않고(동결), 각 레이어에 소수의 파라미터로 구성된 작은 '어댑터'를 추가하여 이 어댑터만 학습시키는 경량화 튜닝 기법입니다. 적은 데이터로도 빠르고 효율적인 학습이 가능한지 검증하기 위해 도입했습니다.

### 3.3. DINOv2 후처리 (Rescoring)
이 방식은 두 단계로 작동하는 '전문가 감수 시스템'입니다.
1.  **1차 탐지**: 먼저, 학습된 YOLOv8 모델이 이미지에서 객체 후보들을 빠르게 찾아냅니다.
2.  **2차 감수**: 각 후보 영역을 잘라내어, 이미지의 전반적인 특징 이해에 뛰어난 DINOv2 모델에게 보여줍니다. DINOv2가 추출한 특징을 입력받은 작은 MLP 네트워크가 해당 후보가 '진짜 객체(True Positive)'일 확률을 다시 계산합니다. 이 점수를 YOLOv8의 원래 신뢰도와 결합하여 최종 점수를 결정합니다.

### 3.4. DINOv2 지식 증류 (Knowledge Distillation)
본 프로젝트의 핵심 가설을 검증하는 방법론입니다. 학습 과정 자체에 두 모델이 함께 참여합니다.
-   **선생님 모델**: DINOv2가 이미지의 풍부한 특징(Feature Map)을 추출합니다. 이 특징은 DINOv2의 '생각의 과정'에 해당하며, 학습 과정에서 변하지 않습니다.
-   **학생 모델**: YOLOv8은 기존의 방식대로 정답을 맞추려고 노력함과 동시에, 자신의 중간 특징 맵이 DINOv2 선생님의 특징 맵과 유사해지도록 추가적으로 학습합니다.
-   **목표**: 이 과정을 통해, YOLOv8 모델 자체가 DINOv2의 시각적 이해 능력을 내재화하여, 별도의 후처리 없이도 단독으로 더 높은 성능을 내는 것을 목표로 합니다.


## 4. 실험 결과 및 상세 분석

### 4.1. 최종 성능 비교표

| 실험 (Experiment) | 학습 에포크 | **최종 성능 (mAP50-95)** | 정밀도 (Precision) | 재현율 (Recall) |
| :--- | :---: | :---: | :---: | :---: |
| Baseline (YOLOv8 단독) | 10 에포크 | `0.327` | 0.598 | 0.445 |
| **Baseline (YOLOv8 단독)** | **50 에포크** | **`0.356`** | 0.656 | 0.471 |
| 지식 증류 (DINOv2 선생님) | 10 에포크 | `0.326` | - | - |
| **지식 증류 (DINOv2 선생님)** | **50 에포크** | `0.352` | **0.660** | **0.474** |

### 4.2. 결과 분석: 숫자에 담긴 의미 해석

#### 최고의 종합 점수(mAP)는 Baseline
정량적인 종합 평가 지표인 **mAP50-95** 점수는 **Baseline 모델을 50 에포크 동안 충분히 학습**시킨 경우가 `0.356`으로 가장 높았습니다. 이는 YOLOv8 모델이 '객체 탐지'라는 특정 작업에 고도로 최적화되어 있으며, 충분한 학습 시간만 주어진다면 스스로 최적의 성능을 찾아갈 수 있음을 의미합니다.

#### 더 신뢰성 있는 모델은 '지식 증류'
하지만 mAP 점수가 전부는 아닙니다. 세부 지표를 분석했을 때, **지식 증류 모델**은 mAP 점수가 약간 낮음에도 불구하고 실제 적용 환경에서 더 중요할 수 있는 두 가지 측면에서 Baseline 모델을 능가했습니다.

1.  **더 높은 정밀도 (Precision: 0.660 > 0.656)**: 정밀도는 "모델이 예측한 것들 중 얼마나 많은 것이 진짜인가?"를 측정합니다. 지식 증류 모델의 정밀도가 더 높다는 것은, **헛다리를 짚는 오탐지(False Positive)가 더 적다**는 것을 의미합니다. 이는 DINOv2의 폭넓은 시각적 이해력이 YOLOv8에게 전달되어, 애매한 배경을 객체로 착각하는 실수를 줄여준 덕분입니다. 이는 결과의 '깔끔함'과 '신뢰성'으로 직결됩니다.

2.  **더 높은 재현율 (Recall: 0.474 > 0.471)**: 재현율은 "실제 정답들 중 모델이 얼마나 많이 찾아냈는가?"를 측정합니다. 지식 증류 모델의 재현율이 더 높다는 것은, **찾아야 할 객체를 놓치는 경우가 더 적다**는 것을 의미합니다. 이는 특히 본 프로젝트의 목표였던 **겹치거나 작은 객체에 대한 대응 능력이 향상**되었음을 시사합니다.

결론적으로, mAP 점수의 미세한 차이는 Baseline 모델이 바운딩 박스를 더 타이트하게 그리는 능력에서 얻은 점수일 수 있습니다. 하지만 오탐지가 적고 탐지 누락이 적은 **지식 증류 모델이 실제 산업 현장에서 더 안정적이고 예측 가능한 시스템을 구축하는 데 유리**하다고 판단할 수 있습니다.

### 4.3. 시각적 결과 비교

아래는 동일한 어려운 이미지에 대한 두 최고 성능 모델의 예측 결과입니다. 지식 증류 모델이 불필요한 오탐지를 줄이고 겹친 객체를 더 안정적으로 탐지하는 것을 시각적으로 확인할 수 있습니다.

| Baseline 모델 (mAP: 0.356) | 지식 증류 모델 (mAP: 0.352) |
| :---: | :---: |
| *[여기에 Baseline 모델의 예측 이미지 삽입]* | *[여기에 지식 증류 모델의 예측 이미지 삽입]* |
| 오탐지가 일부 존재하며, 겹친 객체에 대한 신뢰도가 다소 불안정합니다. | **오탐지가 눈에 띄게 줄었으며**, 복잡한 상황에서도 더 일관된 탐지 결과를 보여줍니다. |


## 5. 최종 결론

본 프로젝트를 통해, 과일 탐지 데이터셋 환경에서는 다음과 같은 결론을 도출했습니다.

> **정량적인 종합 점수(mAP)는 표준 YOLOv8 미세조정 방식이 가장 높았지만, 실제 현장에서 더 중요한 오탐지 감소 및 탐지 안정성 측면에서는 DINOv2 지식 증류 모델이 더 우수한 질적 성능을 보여주었습니다.**

따라서 최종적으로 '더 똑똑하고 신뢰성 있는 모델'이라는 관점에서 **지식 증류 모델을 이 프로젝트의 가장 성공적인 결과물로 선정**합니다. 이는 단순히 가장 높은 점수를 추구하는 것을 넘어, 실제 문제 해결에 가장 적합한 모델을 선택하는 과정의 중요성을 보여줍니다.


## 6. 사용 방법

### 6.1. 환경 설정

### 6.2. 프로젝트 클론
git clone [https://github.com/newkimjiwon/YOLOv8-LoRA-DINOv2-Rescoring-for-Fruit-Counting.git](https://github.com/newkimjiwon/YOLOv8-LoRA-DINOv2-Rescoring-for-Fruit-Counting)
cd Dolo

### 6.3. Conda 가상환경 생성 및 활성화
environment.yaml 파일이 제공될 경우 아래 명령어로 한번에 설치 가능합니다.
conda env create -f environment.yaml
conda activate dolo

### 6.4. 데이터셋 준비
1.  [Kaggle Fruit Detection Dataset](https://www.kaggle.com/datasets/lakshaytyagi01/fruit-detection)에서 데이터셋을 다운로드합니다.
2.  다운로드한 파일의 압축을 해제하고, 아래와 같은 구조로 `1_data/` 폴더 내에 배치합니다.
    ```
    /Dolo/
    └── 1_data/
        └── Fruits-detection/
            ├── train/
            ├── valid/
            ├── test/
            └── data.yaml
    ```
3.  `1_data/Fruits-detection/data.yaml` 파일의 경로가 올바르게 설정되었는지 확인합니다.

### 6.5. 학습 실행
모든 학습 스크립트는 프로젝트 최상위 폴더(`/Dolo_Project`)에서 실행합니다.

* **Baseline / LoRA 학습**
    ```
    # Baseline 학습 (50 에포크)
    python 2_src/train_yolo.py --data 1_data/Fruits-detection/data.yaml --model 3_weights/base/yolov8s.pt --epochs 50 --name y8s_baseline_50e

    # LoRA 학습 (50 에포크)
    python 2_src/train_yolo.py --data 1_data/Fruits-detection/data.yaml --model 3_weights/base/yolov8s.pt --epochs 50 --name y8s_lora_50e --use_lora
    ```

* **DINOv2 지식 증류 학습**
    ```
    python 2_src/train_distillation.py
    ```

### 6.4. 추론 실행
* **DINOv2 후처리(Rescoring) 추론 비교**
    ```
    python 2_src/infer_rescore.py \
      --img_dir 1_data/Fruits-detection/valid/images \
      --yolo_weights [학습된 YOLO 가중치 경로] \
      --mlp_weights [학습된 MLP 가중치 경로]
    ```


## 7. 시스템 사양

-   **GPU**: NVIDIA GeForce RTX 3090 (24GB)
-   **System**: Ubuntu 22.04 (WSL2)
-   **Framework**: PyTorch 2.1.0